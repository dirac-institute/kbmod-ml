[general]
use_gpu = true

# Destination of log messages
# 'stderr' and 'stdout' specify the console.
log_destination = "stderr"
# A path name specifies a file e.g.
# log = "fibad_log.txt"

# Lowest log level to emit.
# As you go down the list, fibad will become more verbose in the log.
#
# log_level = "critical" # Only emit the most severe of errors
# log_level = "error"    # Emit all errors
# log_level = "warning"  # Emit warnings and all errors
log_level = "info"     # Emit informational messages, warnings and all errors
# log_level = "debug"    # Very verbose, emit all log messages.

[download]
sw = "22asec"
sh = "22asec"
filter = ["HSC-G", "HSC-R", "HSC-I", "HSC-Z", "HSC-Y"]
type = "coadd"
rerun = "pdr3_wide"
username = "mtauraso@local"
password = "cCw+nX53lmNLHMy+JbizpH/dl4t7sxljiNm6a7k1"
max_connections = 2
fits_file = "../hscplay/temp.fits"
cutout_dir = "../hscplay/cutouts/"
offset = 0
num_sources = 500

# These control the downloader's HTTP requests and retries
# `retry_wait` How long to wait before retrying a failed HTTP request in seconds. Default 30s
retry_wait = 30
# `retries` How many times to retry a failed HTTP request before moving on to the next one. Default 3 times
retries = 3
# `timepout` How long should we wait to get a full HTTP response from the server. Default 3600s (1hr)
timeout = 3600
# `chunksize` How many sky location rectangles should we request in a single request. Default is 990
chunksize = 990

[model]
# The name of the built-in model to use or the libpath to an external model
# e.g. "user_package.submodule.ExternalModel" or "ExampleAutoencoder"
name = "kbmod_ml.models.cnn.CNN"

weights_filepath = "example_model.pth"
epochs = 10

[data_loader]
# Name of the built-in data loader to use or the libpath to an external data loader
# e.g. "user_package.submodule.ExternalDataLoader" or "HSCDataLoader"
name = "CifarDataLoader"
# name = "HSCDataLoader"

# Directory path where the data is stored
path = "/home/drew/code/fibad/data/"

# Default PyTorch DataLoader parameters
batch_size = 10
shuffle = true
num_workers = 10

[predict]
batch_size = 32
